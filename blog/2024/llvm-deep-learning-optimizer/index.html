<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Building an LLVM-Based Deep Learning Optimizer from Scratch | Mudit Bhargava </title> <meta name="author" content="Mudit Bhargava"> <meta name="description" content="A deep dive into generating optimized LLVM IR for deep learning kernels with SIMD vectorization, FMA, and cache-friendly patterns"> <meta name="keywords" content="Signal processing, financial modeling, Machine Learning/AI, FPGA Development, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%99%8B%F0%9F%8F%BB%E2%80%8D%E2%99%82%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://muditbhargava66.github.io/blog/2024/llvm-deep-learning-optimizer/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Mudit</span> Bhargava </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item "> <a class="nav-link" href="/my-notes/">notes </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/people/">people</a> <a class="dropdown-item " href="/photography/">photography</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">teaching</a> </div> </li> <li class="nav-item"> <button id="search-toggle" class="nav-link search-btn" title="Search (⌘K)"> <i class="fa-solid fa-magnifying-glass"></i> <span class="search-shortcut">⌘K</span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div id="search-modal" class="search-modal" style="display: none;"> <div class="search-modal-backdrop" onclick="closeSearchModal()"></div> <div class="search-modal-content"> <div class="search-modal-header"> <div class="search-input-wrapper"> <i class="fa-solid fa-magnifying-glass search-input-icon"></i> <input type="text" id="search-input" placeholder="Search pages, posts, projects..." autocomplete="off"> <span class="search-shortcut-hint">ESC</span> </div> </div> <div class="search-modal-body" id="search-results"> <div class="search-hint"> <p>Type to search across all content...</p> <div class="search-shortcuts-help"> <span><kbd>↑</kbd><kbd>↓</kbd> to navigate</span> <span><kbd>Enter</kbd> to select</span> <span><kbd>ESC</kbd> to close</span> </div> </div> </div> </div> </div> <script>!function(){function e(){s.style.display="flex",a.value="",a.focus(),document.body.style.overflow="hidden"}async function t(){try{const e=await fetch("/assets/js/search-data.json");e.ok&&(r=await e.json())}catch(e){r=[{title:"Home",url:"/",type:"page"},{title:"Publications",url:"/publications/",type:"page"},{title:"Projects",url:"/projects/",type:"page"},{title:"Blog",url:"/blog/",type:"page"},{title:"CV",url:"/cv/",type:"page"},{title:"Repositories",url:"/repositories/",type:"page"},{title:"Teaching",url:"/teaching/",type:"page"}]}}function n(e){if(!e.trim())return void(l.innerHTML='\n        <div class="search-hint">\n          <p>Type to search across all content...</p>\n          <div class="search-shortcuts-help">\n            <span><kbd>\u2191</kbd><kbd>\u2193</kbd> to navigate</span>\n            <span><kbd>Enter</kbd> to select</span>\n            <span><kbd>ESC</kbd> to close</span>\n          </div>\n        </div>\n      ');const t=r.filter(t=>t.title.toLowerCase().includes(e.toLowerCase())||t.content&&t.content.toLowerCase().includes(e.toLowerCase())).slice(0,8);0!==t.length?l.innerHTML=t.map((e,t)=>`\n      <a href="${e.url}" class="search-result-item ${0===t?"active":""}">\n        <span class="search-result-type">${e.type||"page"}</span>\n        <span class="search-result-title">${e.title}</span>\n      </a>\n    `).join(""):l.innerHTML='<div class="search-no-results">No results found</div>'}const s=document.getElementById("search-modal"),a=document.getElementById("search-input"),l=document.getElementById("search-results"),o=document.getElementById("search-toggle");let r=[];window.closeSearchModal=function(){s.style.display="none",document.body.style.overflow=""},document.addEventListener("keydown",function(t){(t.metaKey||t.ctrlKey)&&"k"===t.key&&(t.preventDefault(),"none"===s.style.display||""===s.style.display?e():closeSearchModal()),"Escape"===t.key&&"flex"===s.style.display&&closeSearchModal()}),o&&o.addEventListener("click",e),a&&(a.addEventListener("input",function(e){n(e.target.value)}),a.addEventListener("keydown",function(e){const t=l.querySelectorAll(".search-result-item"),n=l.querySelector(".search-result-item.active");if("ArrowDown"===e.key&&t.length>0){e.preventDefault();let s=0;n&&(n.classList.remove("active"),s=(Array.from(t).indexOf(n)+1)%t.length),t[s].classList.add("active")}else if("ArrowUp"===e.key&&t.length>0){e.preventDefault();let s=t.length-1;n&&(n.classList.remove("active"),s=(Array.from(t).indexOf(n)-1+t.length)%t.length),t[s].classList.add("active")}else"Enter"===e.key&&n&&(e.preventDefault(),window.location.href=n.href)})),t()}();</script> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Building an LLVM-Based Deep Learning Optimizer from Scratch</h1> <p class="post-meta"> Created in December 25, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/llvm"> <i class="fa-solid fa-hashtag fa-sm"></i> llvm</a>   <a href="/blog/tag/compilers"> <i class="fa-solid fa-hashtag fa-sm"></i> compilers</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> optimization</a>     ·   <a href="/blog/category/projects"> <i class="fa-solid fa-tag fa-sm"></i> projects</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>When it comes to deep learning performance, most engineers reach for established frameworks like PyTorch or TensorFlow. But what happens underneath these abstractions? How do operations like convolution or ReLU get translated into efficient machine code?</p> <p>This post explores my journey building the <a href="https://github.com/muditbhargava66/llvm-dl-optimizer" rel="external nofollow noopener" target="_blank">LLVM Deep Learning Optimizer</a>, a project that generates optimized LLVM Intermediate Representation (IR) for common deep learning primitives. Along the way, we’ll discover the optimization techniques that make modern neural networks fast.</p> <h2 id="the-problem-bridging-high-level-operations-and-hardware">The Problem: Bridging High-Level Operations and Hardware</h2> <p>Consider a simple ReLU activation applied to a tensor of 1 million elements:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>  <span class="c1"># Applied element-wise
</span></code></pre></div></div> <p>A naive implementation processes one element at a time. But modern CPUs have SIMD (Single Instruction, Multiple Data) registers that can handle 8 floats simultaneously. That’s an easy 8x speedup sitting on the table—if your code knows how to use it.</p> <h2 id="enter-llvm">Enter LLVM</h2> <p>LLVM is a compiler infrastructure that provides an intermediate representation (IR) sitting between high-level code and machine instructions. By generating optimized LLVM IR, we can:</p> <ol> <li> <strong>Target multiple architectures</strong> - The same IR compiles to x86, ARM, or custom hardware</li> <li> <strong>Apply advanced optimizations</strong> - LLVM’s optimization passes are battle-tested</li> <li> <strong>Maintain precision</strong> - We control exactly which floating-point operations occur</li> </ol> <h2 id="key-optimization-techniques">Key Optimization Techniques</h2> <h3 id="1-simd-vectorization">1. SIMD Vectorization</h3> <p>Instead of processing one element at a time, vectorized code processes multiple elements in parallel:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Scalar: 1024 iterations</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">1024</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="c1">// Vectorized (8-wide): 128 iterations</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">1024</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="o">:</span><span class="n">i</span><span class="o">+</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="n">vmax</span><span class="p">(</span><span class="n">vzero</span><span class="p">,</span> <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="o">:</span><span class="n">i</span><span class="o">+</span><span class="mi">8</span><span class="p">]);</span>
</code></pre></div></div> <p>The optimizer automatically emits vector load/store instructions and uses SIMD comparison operations, yielding 4-8x throughput improvements for activation functions.</p> <h3 id="2-fused-multiply-add-fma">2. Fused Multiply-Add (FMA)</h3> <p>Convolution and batch normalization perform many multiply-add sequences. Modern CPUs have dedicated FMA instructions that:</p> <ul> <li>Execute multiply and add in a single cycle</li> <li>Provide better numerical precision (reduced rounding errors)</li> <li>Double the effective FLOP throughput</li> </ul> <p>The optimizer recognizes patterns like <code class="language-plaintext highlighter-rouge">a * b + c</code> and emits FMA instructions directly.</p> <h3 id="3-loop-fusion">3. Loop Fusion</h3> <p>Consider batch normalization, which involves multiple passes over data:</p> <ol> <li>Compute mean</li> <li>Compute variance</li> <li>Normalize</li> </ol> <p>Naive implementations make three separate passes, flushing CPU caches between each. Loop fusion combines these operations, keeping data in cache and reducing memory bandwidth pressure by 2-3x.</p> <h2 id="architecture-overview">Architecture Overview</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌────────────────────────────────────────────────────────────┐
│                   LLVM DL Optimizer                        │
├────────────────────────────────────────────────────────────┤
│  Kernel Layer                                              │
│  ┌──────────┐ ┌────────────┐ ┌─────────┐ ┌─────────┐       │
│  │Activation│ │Convolution │ │ Pooling │ │ Softmax │       │
│  │ 8 types  │ │ NCHW + FMA │ │Max/Avg  │ │ 3-pass  │       │
│  └──────────┘ └────────────┘ └─────────┘ └─────────┘       │
├────────────────────────────────────────────────────────────┤
│  Optimization Layer                                        │
│  ┌────────────┐ ┌────────────┐ ┌────────────────┐          │
│  │Auto-Vector │ │ Loop Fusion│ │ Data Layout    │          │
│  │  ization   │ │    Pass    │ │ Transform      │          │
│  └────────────┘ └────────────┘ └────────────────┘          │
├────────────────────────────────────────────────────────────┤
│                LLVM 18-21 Infrastructure                   │
│        (Opaque Pointers, FixedVectorType, FMA/Exp)         │
└────────────────────────────────────────────────────────────┘
</code></pre></div></div> <h2 id="benchmarks">Benchmarks</h2> <p>Testing on an Intel Core i9 with AVX-512 support:</p> <table> <thead> <tr> <th>Kernel</th> <th>Without Optimization</th> <th>With Optimization</th> <th>Speedup</th> </tr> </thead> <tbody> <tr> <td>ReLU (1M elements)</td> <td>0.8ms</td> <td>0.12ms</td> <td>6.7x</td> </tr> <tr> <td>3x3 Convolution</td> <td>45ms</td> <td>18ms</td> <td>2.5x</td> </tr> <tr> <td>Batch Normalization</td> <td>12ms</td> <td>4.2ms</td> <td>2.9x</td> </tr> <tr> <td>Max Pooling 2x2</td> <td>8.5ms</td> <td>2.1ms</td> <td>4.0x</td> </tr> </tbody> </table> <h2 id="when-to-use-this">When to Use This</h2> <p>This project is ideal for:</p> <ul> <li> <strong>Learning</strong> - Understanding how compilers optimize DL operations</li> <li> <strong>Research</strong> - Experimenting with novel optimization techniques</li> <li> <strong>Custom hardware</strong> - Generating kernels for specialized accelerators</li> <li> <strong>Edge deployment</strong> - When you need maximum CPU efficiency</li> </ul> <p>It’s not meant to replace PyTorch or TensorFlow for production training.</p> <h2 id="getting-started">Getting Started</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/muditbhargava66/llvm-dl-optimizer.git
<span class="nb">cd </span>llvm-dl-optimizer
<span class="nb">mkdir </span>build <span class="o">&amp;&amp;</span> <span class="nb">cd </span>build
cmake <span class="nt">-DCMAKE_BUILD_TYPE</span><span class="o">=</span>Release ..
make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>

<span class="c"># Generate optimized IR and run demo</span>
./llvm-dl-optimizer <span class="nt">--demo</span> <span class="nt">-v</span> <span class="nt">-o</span> output.ll
</code></pre></div></div> <h2 id="conclusion">Conclusion</h2> <p>Building a deep learning optimizer from scratch reveals the layers of optimization happening beneath our abstractions. From SIMD vectorization to FMA fusion to cache-conscious code generation, there’s an entire world of engineering that transforms simple mathematical operations into blazingly fast implementations.</p> <p>The full source code, documentation, and benchmarks are available at <a href="https://github.com/muditbhargava66/llvm-dl-optimizer" rel="external nofollow noopener" target="_blank">github.com/muditbhargava66/llvm-dl-optimizer</a>.</p> <p><em>Have questions or ideas for additional optimizations? Feel free to open an issue or contribute!</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/pyxlstm-extended-lstm/">Implementing Extended LSTM (xLSTM) - A Modern Take on Recurrent Networks</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/distill/">a distill-style blog post</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/code-diff/">a post with code diff</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2015/code/">a post with code</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/echarts/">a post with echarts</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"muditbhargava66/muditbhargava66.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Mudit Bhargava. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZDVK3FWXZP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-ZDVK3FWXZP");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?fa0110e8b42cec56ce96d912fd4bde74"></script> <script>addBackToTop();</script> </body> </html>